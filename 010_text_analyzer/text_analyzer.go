package main

import (
	"bufio"
	"flag"
	"fmt"
	"io/ioutil"
	"os"
	"regexp"
	"sort"
	"strings"
	"unicode"
	"unicode/utf8"
)

/**
æ–‡æœ¬åˆ†æå·¥å…·
	ä½¿ç”¨GoåŸºç¡€è¯­æ³•å®ç°æ–‡æœ¬æ–‡ä»¶åˆ†æ
	æ”¯æŒç»Ÿè®¡æ–‡æœ¬çš„å¤šç§æŒ‡æ ‡
	åŒ…æ‹¬å­—ç¬¦æ•°ã€å•è¯æ•°ã€è¡Œæ•°ã€æ®µè½æ•°ç­‰
	æ”¯æŒè¯é¢‘åˆ†æå’Œæ–‡æœ¬æ‘˜è¦
	å±•ç¤ºGoè¯­è¨€æ–‡ä»¶æ“ä½œã€æ­£åˆ™è¡¨è¾¾å¼ã€æ’åºç­‰ç‰¹æ€§
*/

// TextStats æ–‡æœ¬ç»Ÿè®¡ç»“æ„ä½“
type TextStats struct {
	Filename       string          // æ–‡ä»¶å
	Characters     int             // å­—ç¬¦æ•°ï¼ˆåŒ…å«ç©ºæ ¼ï¼‰
	CharactersNoWS int             // å­—ç¬¦æ•°ï¼ˆä¸å«ç©ºæ ¼ï¼‰
	Words          int             // å•è¯æ•°
	Lines          int             // è¡Œæ•°
	Paragraphs     int             // æ®µè½æ•°
	Sentences      int             // å¥å­æ•°
	ChineseChars   int             // ä¸­æ–‡å­—ç¬¦æ•°
	EnglishWords   int             // è‹±æ–‡å•è¯æ•°
	Numbers        int             // æ•°å­—å­—ç¬¦æ•°
	Punctuation    int             // æ ‡ç‚¹ç¬¦å·æ•°
	WordFreq       map[string]int  // è¯é¢‘ç»Ÿè®¡
	TopWords       []WordFrequency // é«˜é¢‘è¯æ±‡
	ReadingTime    float64         // é¢„ä¼°é˜…è¯»æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
}

// WordFrequency è¯é¢‘ç»“æ„ä½“
type WordFrequency struct {
	Word  string
	Count int
}

// AnalysisConfig åˆ†æé…ç½®ç»“æ„ä½“
type AnalysisConfig struct {
	ShowWordFreq  bool   // æ˜¾ç¤ºè¯é¢‘åˆ†æ
	TopWordsCount int    // æ˜¾ç¤ºé«˜é¢‘è¯æ•°é‡
	MinWordLength int    // æœ€å°å•è¯é•¿åº¦
	IgnoreCase    bool   // å¿½ç•¥å¤§å°å†™
	OutputFormat  string // è¾“å‡ºæ ¼å¼ (text/json)
	ReadingSpeed  int    // é˜…è¯»é€Ÿåº¦ï¼ˆå­—/åˆ†é’Ÿï¼‰
}

// å¸¸ç”¨åœç”¨è¯ï¼ˆä¸­è‹±æ–‡ï¼‰
var stopWords = map[string]bool{
	"çš„": true, "äº†": true, "åœ¨": true, "æ˜¯": true, "æˆ‘": true, "æœ‰": true, "å’Œ": true, "å°±": true,
	"ä¸": true, "äºº": true, "éƒ½": true, "ä¸€": true, "ä¸€ä¸ª": true, "ä¸Š": true, "ä¹Ÿ": true, "å¾ˆ": true,
	"åˆ°": true, "è¯´": true, "è¦": true, "å»": true, "ä½ ": true, "ä¼š": true, "ç€": true, "æ²¡æœ‰": true,
	"çœ‹": true, "å¥½": true, "è‡ªå·±": true, "è¿™": true, "å¥¹": true, "ä»–": true, "ä½†æ˜¯": true, "é‚£": true,
	"the": true, "be": true, "to": true, "of": true, "and": true, "a": true, "in": true, "that": true,
	"have": true, "i": true, "it": true, "for": true, "not": true, "on": true, "with": true, "he": true,
	"as": true, "you": true, "do": true, "at": true, "this": true, "but": true, "his": true, "by": true,
	"from": true, "they": true, "we": true, "say": true, "her": true, "she": true, "or": true, "an": true,
}

// åˆ†ææ–‡æœ¬æ–‡ä»¶
func analyzeText(filename string, config *AnalysisConfig) (*TextStats, error) {
	// è¯»å–æ–‡ä»¶å†…å®¹
	content, err := ioutil.ReadFile(filename)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–æ–‡ä»¶å¤±è´¥: %v", err)
	}

	text := string(content)
	stats := &TextStats{
		Filename: filename,
		WordFreq: make(map[string]int),
	}

	// åŸºç¡€ç»Ÿè®¡
	stats.Characters = utf8.RuneCountInString(text)
	stats.CharactersNoWS = utf8.RuneCountInString(strings.ReplaceAll(strings.ReplaceAll(text, " ", ""), "\t", ""))
	stats.Lines = countLines(text)
	stats.Paragraphs = countParagraphs(text)
	stats.Sentences = countSentences(text)

	// å­—ç¬¦ç±»å‹ç»Ÿè®¡
	for _, char := range text {
		switch {
		case unicode.Is(unicode.Han, char):
			stats.ChineseChars++
		case unicode.IsDigit(char):
			stats.Numbers++
		case unicode.IsPunct(char):
			stats.Punctuation++
		}
	}

	// å•è¯ç»Ÿè®¡å’Œè¯é¢‘åˆ†æ
	words := extractWords(text, config)
	stats.Words = len(words)

	englishWordCount := 0
	for _, word := range words {
		if isEnglishWord(word) {
			englishWordCount++
		}

		// è¯é¢‘ç»Ÿè®¡
		if config.ShowWordFreq {
			key := word
			if config.IgnoreCase {
				key = strings.ToLower(word)
			}
			if len(key) >= config.MinWordLength && !stopWords[key] {
				stats.WordFreq[key]++
			}
		}
	}
	stats.EnglishWords = englishWordCount

	// ç”Ÿæˆé«˜é¢‘è¯åˆ—è¡¨
	if config.ShowWordFreq {
		stats.TopWords = getTopWords(stats.WordFreq, config.TopWordsCount)
	}

	// è®¡ç®—é¢„ä¼°é˜…è¯»æ—¶é—´
	totalReadableChars := stats.ChineseChars + stats.EnglishWords
	stats.ReadingTime = float64(totalReadableChars) / float64(config.ReadingSpeed)

	return stats, nil
}

// ç»Ÿè®¡è¡Œæ•°
func countLines(text string) int {
	scanner := bufio.NewScanner(strings.NewReader(text))
	lines := 0
	for scanner.Scan() {
		lines++
	}
	return lines
}

// ç»Ÿè®¡æ®µè½æ•°
func countParagraphs(text string) int {
	paragraphs := strings.Split(strings.TrimSpace(text), "\n\n")
	return len(paragraphs)
}

// ç»Ÿè®¡å¥å­æ•°
func countSentences(text string) int {
	// ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¥å­ç»“å°¾
	re := regexp.MustCompile(`[.!?ã€‚ï¼ï¼Ÿ]+`)
	matches := re.FindAllString(text, -1)
	return len(matches)
}

// æå–å•è¯
func extractWords(text string, config *AnalysisConfig) []string {
	// ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å•è¯ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
	re := regexp.MustCompile(`[\p{L}\p{N}]+`)
	words := re.FindAllString(text, -1)

	var filteredWords []string
	for _, word := range words {
		if len(word) >= config.MinWordLength {
			filteredWords = append(filteredWords, word)
		}
	}

	return filteredWords
}

// åˆ¤æ–­æ˜¯å¦ä¸ºè‹±æ–‡å•è¯
func isEnglishWord(word string) bool {
	for _, char := range word {
		if char > 127 {
			return false
		}
	}
	return true
}

// è·å–é«˜é¢‘è¯
func getTopWords(wordFreq map[string]int, topCount int) []WordFrequency {
	var words []WordFrequency
	for word, count := range wordFreq {
		words = append(words, WordFrequency{Word: word, Count: count})
	}

	// æŒ‰é¢‘ç‡æ’åº
	sort.Slice(words, func(i, j int) bool {
		return words[i].Count > words[j].Count
	})

	// è¿”å›å‰Nä¸ª
	if len(words) < topCount {
		topCount = len(words)
	}
	return words[:topCount]
}

// æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
func displayStats(stats *TextStats, config *AnalysisConfig) {
	fmt.Printf("æ–‡æœ¬åˆ†æç»“æœ: %s\n", stats.Filename)
	fmt.Println("========================================")

	// åŸºç¡€ç»Ÿè®¡
	fmt.Printf("ğŸ“„ åŸºç¡€ç»Ÿè®¡:\n")
	fmt.Printf("  æ€»å­—ç¬¦æ•°: %d\n", stats.Characters)
	fmt.Printf("  æœ‰æ•ˆå­—ç¬¦æ•°: %d (ä¸å«ç©ºæ ¼)\n", stats.CharactersNoWS)
	fmt.Printf("  å•è¯æ•°: %d\n", stats.Words)
	fmt.Printf("  è¡Œæ•°: %d\n", stats.Lines)
	fmt.Printf("  æ®µè½æ•°: %d\n", stats.Paragraphs)
	fmt.Printf("  å¥å­æ•°: %d\n", stats.Sentences)
	fmt.Println()

	// å­—ç¬¦ç±»å‹ç»Ÿè®¡
	fmt.Printf("ğŸ”¤ å­—ç¬¦ç±»å‹ç»Ÿè®¡:\n")
	fmt.Printf("  ä¸­æ–‡å­—ç¬¦: %d\n", stats.ChineseChars)
	fmt.Printf("  è‹±æ–‡å•è¯: %d\n", stats.EnglishWords)
	fmt.Printf("  æ•°å­—å­—ç¬¦: %d\n", stats.Numbers)
	fmt.Printf("  æ ‡ç‚¹ç¬¦å·: %d\n", stats.Punctuation)
	fmt.Println()

	// é˜…è¯»æ—¶é—´
	fmt.Printf("â±ï¸  é¢„ä¼°é˜…è¯»æ—¶é—´: %.1f åˆ†é’Ÿ\n", stats.ReadingTime)
	fmt.Println()

	// è¯é¢‘åˆ†æ
	if config.ShowWordFreq && len(stats.TopWords) > 0 {
		fmt.Printf("ğŸ“Š é«˜é¢‘è¯æ±‡ (å‰ %d ä¸ª):\n", len(stats.TopWords))
		for i, word := range stats.TopWords {
			fmt.Printf("%2d. %-15s %d æ¬¡\n", i+1, word.Word, word.Count)
		}
		fmt.Println()
	}

	// æ–‡æœ¬å¤æ‚åº¦è¯„ä¼°
	fmt.Printf("ğŸ“ˆ æ–‡æœ¬å¤æ‚åº¦è¯„ä¼°:\n")
	avgWordsPerSentence := float64(stats.Words) / float64(stats.Sentences)
	avgCharsPerWord := float64(stats.CharactersNoWS) / float64(stats.Words)

	fmt.Printf("  å¹³å‡å¥é•¿: %.1f ä¸ªå•è¯\n", avgWordsPerSentence)
	fmt.Printf("  å¹³å‡è¯é•¿: %.1f ä¸ªå­—ç¬¦\n", avgCharsPerWord)

	// å¤æ‚åº¦è¯„çº§
	complexity := "ç®€å•"
	if avgWordsPerSentence > 20 || avgCharsPerWord > 6 {
		complexity = "å¤æ‚"
	} else if avgWordsPerSentence > 15 || avgCharsPerWord > 4 {
		complexity = "ä¸­ç­‰"
	}
	fmt.Printf("  å¤æ‚åº¦ç­‰çº§: %s\n", complexity)
}

// æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
func showHelp() {
	fmt.Println("æ–‡æœ¬åˆ†æå·¥å…·")
	fmt.Println("ç”¨æ³•: text_analyzer [é€‰é¡¹] <æ–‡ä»¶è·¯å¾„>")
	fmt.Println()
	fmt.Println("é€‰é¡¹:")
	fmt.Println("  -freq          æ˜¾ç¤ºè¯é¢‘åˆ†æ (é»˜è®¤: false)")
	fmt.Println("  -top           æ˜¾ç¤ºé«˜é¢‘è¯æ•°é‡ (é»˜è®¤: 10)")
	fmt.Println("  -minlen        æœ€å°å•è¯é•¿åº¦ (é»˜è®¤: 2)")
	fmt.Println("  -ignore-case   å¿½ç•¥å¤§å°å†™ (é»˜è®¤: true)")
	fmt.Println("  -speed         é˜…è¯»é€Ÿåº¦(å­—/åˆ†é’Ÿ) (é»˜è®¤: 200)")
	fmt.Println("  -help          æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
	fmt.Println()
	fmt.Println("ç¤ºä¾‹:")
	fmt.Println("  åˆ†ææ–‡æœ¬æ–‡ä»¶åŸºç¡€ä¿¡æ¯:")
	fmt.Println("  text_analyzer document.txt")
	fmt.Println()
	fmt.Println("  åˆ†æå¹¶æ˜¾ç¤ºè¯é¢‘ç»Ÿè®¡:")
	fmt.Println("  text_analyzer -freq -top 20 document.txt")
	fmt.Println()
	fmt.Println("  è‡ªå®šä¹‰åˆ†æå‚æ•°:")
	fmt.Println("  text_analyzer -freq -top 15 -minlen 3 -speed 180 document.txt")
}

func main() {
	// è§£æå‘½ä»¤è¡Œå‚æ•°
	showWordFreq := flag.Bool("freq", false, "æ˜¾ç¤ºè¯é¢‘åˆ†æ")
	topWordsCount := flag.Int("top", 10, "æ˜¾ç¤ºé«˜é¢‘è¯æ•°é‡")
	minWordLength := flag.Int("minlen", 2, "æœ€å°å•è¯é•¿åº¦")
	ignoreCase := flag.Bool("ignore-case", true, "å¿½ç•¥å¤§å°å†™")
	readingSpeed := flag.Int("speed", 200, "é˜…è¯»é€Ÿåº¦(å­—/åˆ†é’Ÿ)")
	help := flag.Bool("help", false, "æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")

	flag.Parse()

	// æ˜¾ç¤ºå¸®åŠ©
	if *help {
		showHelp()
		os.Exit(0)
	}

	// æ£€æŸ¥æ–‡ä»¶å‚æ•°
	args := flag.Args()
	if len(args) < 1 {
		fmt.Println("é”™è¯¯: è¯·æŒ‡å®šè¦åˆ†æçš„æ–‡ä»¶è·¯å¾„")
		fmt.Println("ä½¿ç”¨ -help æŸ¥çœ‹ä½¿ç”¨è¯´æ˜")
		os.Exit(1)
	}

	filename := args[0]

	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
	if _, err := os.Stat(filename); os.IsNotExist(err) {
		fmt.Printf("é”™è¯¯: æ–‡ä»¶ '%s' ä¸å­˜åœ¨\n", filename)
		os.Exit(1)
	}

	// åˆ›å»ºåˆ†æé…ç½®
	config := &AnalysisConfig{
		ShowWordFreq:  *showWordFreq,
		TopWordsCount: *topWordsCount,
		MinWordLength: *minWordLength,
		IgnoreCase:    *ignoreCase,
		ReadingSpeed:  *readingSpeed,
	}

	// åˆ†ææ–‡æœ¬
	fmt.Printf("æ­£åœ¨åˆ†ææ–‡ä»¶: %s\n\n", filename)
	stats, err := analyzeText(filename, config)
	if err != nil {
		fmt.Printf("åˆ†æå¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// æ˜¾ç¤ºç»“æœ
	displayStats(stats, config)

	fmt.Println("========================================")
	fmt.Println("åˆ†æå®Œæˆ!")
}
